package lib

import (
	"context"
	"fmt"
	"net/url"
	"strings"
	"sync"
	"time"

	"ns-rss/src/app/config"
	"ns-rss/src/app/db"

	"github.com/dlclark/regexp2"
	"github.com/imroc/req/v3"
	"github.com/mmcdole/gofeed"
	"github.com/thoas/go-funk"
	"github.com/zeromicro/go-zero/core/logx"
	"github.com/zeromicro/go-zero/core/rescue"
)

//var history = make(map[int64]map[string]struct{})

// å‘é€è®¡æ•°
//var noticeHistory = make(map[string]int64)

type NsFeed struct {
	sync.Mutex
	ctx          context.Context
	svc          *ServiceCtx
	logger       logx.Logger
	bot          BotNotifier
	msgQueue     chan *NotifyMessage // æ¶ˆæ¯é˜Ÿåˆ—
	Config       *config.Config
	LastUpdate   time.Time
	interval     time.Duration // å½“å‰è¯·æ±‚é—´éš”
	minInterval  time.Duration // æœ€å°é—´éš”
	maxInterval  time.Duration // æœ€å¤§é—´éš”
	successCount int           // è¿ç»­æˆåŠŸæ¬¡æ•°
	failureCount int           // è¿ç»­å¤±è´¥æ¬¡æ•°
}

func NewNsFeed(ctx context.Context, svc *ServiceCtx, config *config.Config) *NsFeed {
	return &NsFeed{
		ctx:         ctx,
		svc:         svc,
		logger:      logx.WithContext(ctx).WithFields(logx.Field("lib", "ns_feed")),
		Config:      config,
		interval:    10 * time.Second,                // åˆå§‹é—´éš”
		minInterval: 10 * time.Second,                // æœ€å°é—´éš”
		maxInterval: 5 * time.Minute,                 // æœ€å¤§é—´éš”
		msgQueue:    make(chan *NotifyMessage, 1000), // åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—ï¼Œç¼“å†²å¤§å°ä¸º1000
	}
}

func (f *NsFeed) SetBot(bot BotNotifier) *NsFeed {
	f.bot = bot

	// å¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹è€…
	go f.startQueueConsumer()

	return f
}

// å¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹è€…ï¼Œæ§åˆ¶æ¶ˆè´¹é€Ÿç‡ä¸ºæ¯ç§’20æ¡æ¶ˆæ¯
func (f *NsFeed) startQueueConsumer() {
	defer rescue.Recover()

	f.logger.Debugw("starting message queue consumer with batching")

	// è®¡ç®—æ¶ˆæ¯å‘é€é—´éš”ï¼Œä¿è¯æ¯ç§’æœ€å¤šå‘é€20æ¡æ¶ˆæ¯
	const interval = time.Millisecond * 50     // 1000ms / 20 = 50ms
	const batchSize = 10                       // æ‰¹å¤„ç†å¤§å°
	const batchWindow = 500 * time.Millisecond // æ‰¹å¤„ç†æ—¶é—´çª—å£

	var messageBatch []*NotifyMessage
	ticker := time.NewTicker(batchWindow)
	defer ticker.Stop()

	// ç”¨äºé™åˆ¶å‘é€é€Ÿç‡çš„æ—¶é—´ç‚¹
	nextSendTime := time.Now()

	for {
		select {
		case <-f.ctx.Done():
			f.logger.Debugw("message queue consumer stopped due to context done")
			return

		case msg := <-f.msgQueue:
			if msg != nil {
				messageBatch = append(messageBatch, msg)
			}

			// å¦‚æœæ‰¹æ¬¡å·²æ»¡ï¼Œç«‹å³å¤„ç†
			if len(messageBatch) >= batchSize {
				now := time.Now()
				// å¦‚æœå·²ç»åˆ°äº†å¯ä»¥å‘é€çš„æ—¶é—´ï¼Œå¤„ç†æ‰¹æ¬¡
				if now.After(nextSendTime) {
					f.processBatch(messageBatch)
					messageBatch = nil
					nextSendTime = now.Add(interval * time.Duration(batchSize))
				}
			}

		case <-ticker.C:
			// å®šæœŸå¤„ç†ç§¯ç´¯çš„æ¶ˆæ¯ï¼Œå³ä½¿æœªè¾¾åˆ°æ‰¹å¤„ç†å¤§å°
			if len(messageBatch) > 0 {
				now := time.Now()
				if now.After(nextSendTime) {
					f.processBatch(messageBatch)
					messageBatch = nil
					nextSendTime = now.Add(interval * time.Duration(len(messageBatch)))
				}
			}
		}
	}
}

// æ‰¹é‡å¤„ç†æ¶ˆæ¯
func (f *NsFeed) processBatch(messages []*NotifyMessage) {
	if len(messages) == 0 || f.bot == nil {
		return
	}

	// æŒ‰èŠå¤©IDåˆ†ç»„
	chatGroups := make(map[int64][]*NotifyMessage)
	for _, msg := range messages {
		if msg.ChatId != nil {
			chatGroups[*msg.ChatId] = append(chatGroups[*msg.ChatId], msg)
		}
	}

	// å¯¹æ¯ä¸ªèŠå¤©IDçš„æ¶ˆæ¯è¿›è¡Œå¤„ç†
	for chatID, msgs := range chatGroups {
		f.logger.Debugw("processing message batch", logx.Field("chatId", chatID), logx.Field("count", len(msgs)))

		// ä½¿ç”¨æœ‰é™é€Ÿç‡å‘é€å•æ¡æ¶ˆæ¯
		for _, msg := range msgs {
			f.bot.Notify(*msg)
			time.Sleep(50 * time.Millisecond) // æ§åˆ¶å‘é€é€Ÿç‡
		}
	}
}

func (f *NsFeed) Add(msg NotifyMessage) {
	// å°†æ¶ˆæ¯æ·»åŠ åˆ°é˜Ÿåˆ—
	select {
	case f.msgQueue <- &msg:
		f.logger.Debugw("added message to queue", logx.Field("chatId", msg.ChatId))
	default:
		// é˜Ÿåˆ—å·²æ»¡ï¼Œè®°å½•æ—¥å¿—
		f.logger.Infow("message queue is full, message dropped", logx.Field("chatId", msg.ChatId))
	}
}

// ä½¿ç”¨ç¼“å­˜å­˜å‚¨å·²ç¼–è¯‘çš„æ­£åˆ™è¡¨è¾¾å¼
var regexCache = sync.Map{}

// è·å–ç¼“å­˜çš„æ­£åˆ™è¡¨è¾¾å¼
func getCachedRegex(keyword string) (*regexp2.Regexp, bool) {
	if re, ok := regexCache.Load(keyword); ok {
		return re.(*regexp2.Regexp), true
	}

	re, err := regexp2.Compile(keyword, regexp2.IgnoreCase)
	if err != nil {
		return nil, false
	}

	regexCache.Store(keyword, re)
	return re, true
}

// ä¼˜åŒ–åçš„æ­£åˆ™åŒ¹é…å‡½æ•°
func hasKeywordWithRegexCached(title string, keyword string) bool {
	re, ok := getCachedRegex(keyword)
	if !ok {
		return false
	}
	r, _ := re.MatchString(title)
	return r
}

func hasKeyword(title string, keywords []string) bool {
	title = strings.ToLower(title)
	for _, keyword := range keywords {
		// æ£€æŸ¥æ˜¯å¦åŒ…å«ç‰¹æ®Šå­—ç¬¦ï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦æ­£åˆ™åŒ¹é…
		needsRegex := strings.ContainsAny(keyword, "^$.*+?()[]{}|\\~+")

		if !needsRegex {
			// ç®€å•çš„å­—ç¬¦ä¸²åŒ…å«æ£€æŸ¥
			if strings.Contains(title, strings.ToLower(keyword)) {
				return true
			}
			continue
		}

		// é¦–å…ˆå°è¯•è¡¨è¾¾å¼åŒ¹é…ï¼Œè¿™é€šå¸¸æ›´å¿«
		if hasKeywordWithExpression(title, keyword) {
			return true
		}

		// å¦‚æœè¡¨è¾¾å¼åŒ¹é…å¤±è´¥ï¼Œå†å°è¯•æ­£åˆ™åŒ¹é…
		if hasKeywordWithRegexCached(title, keyword) {
			return true
		}
	}
	return false
}

// matchExpression åŒ¹é…è¡¨è¾¾å¼å‡½æ•°
// expr: è¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼Œæ”¯æŒ + (ä¸), | (æˆ–), ~ (æ’é™¤)
// text: è¦åŒ¹é…çš„æ–‡æœ¬
// è¿”å›: æ˜¯å¦åŒ¹é…çš„å¸ƒå°”å€¼
func matchExpression(expr, text string) bool {
	// é¦–å…ˆå¤„ç† | (æˆ–) è¿ç®—ç¬¦ï¼Œå°†è¡¨è¾¾å¼æŒ‰ | åˆ†å‰²
	orParts := strings.Split(expr, "|")

	// ä»»æ„ä¸€ä¸ª or æ¡ä»¶æ»¡è¶³å³è¿”å› true
	for _, orPart := range orParts {
		if matchAndExpression(strings.TrimSpace(orPart), text) {
			return true
		}
	}
	return false
}

// matchAndExpression å¤„ç† + (ä¸) å’Œ ~ (æ’é™¤) çš„é€»è¾‘
func matchAndExpression(expr, text string) bool {
	// å°†è¡¨è¾¾å¼æŒ‰ + åˆ†å‰²
	andParts := strings.Split(expr, "+")

	// æ£€æŸ¥æ¯ä¸ªæ¡ä»¶
	for _, part := range andParts {
		part = strings.TrimSpace(part)
		if len(part) == 0 {
			continue
		}

		// å¤„ç†æ’é™¤(~)é€»è¾‘
		if strings.HasPrefix(part, "~") {
			excludeTerm := strings.TrimPrefix(part, "~")
			if strings.Contains(text, excludeTerm) {
				return false
			}
		} else {
			// å¤„ç†åŒ…å«é€»è¾‘
			if !strings.Contains(text, part) {
				return false
			}
		}
	}
	return true
}

func hasKeywordWithExpression(title string, keyword string) bool {

	return matchExpression(keyword, title)

}

type MessageOption struct {
	ChatId   int64
	FeedName string
	Keywords []string
}

func removeHash(u string) (string, error) {
	parsedUrl, err := url.Parse(u)
	if err != nil {
		return "", err
	}
	// å°†é”šç‚¹éƒ¨åˆ†è®¾ç½®ä¸ºç©º
	parsedUrl.Fragment = ""
	return parsedUrl.String(), nil
}

func (f *NsFeed) sendMessage(c *MessageOption, feedName string, items []*gofeed.Item) {
	if len(items) == 0 {
		return
	}

	// 1. æ”¶é›†æ‰€æœ‰ URL å’Œç¬¦åˆå…³é”®è¯çš„æ¡ç›®
	urls := make([]string, 0, len(items))
	urlToItem := make(map[string]*gofeed.Item)

	for _, item := range items {
		cleanUrl, err := removeHash(item.Link)
		if err != nil || cleanUrl == "" {
			continue
		}

		// åªå¤„ç†ç¬¦åˆå…³é”®è¯æ¡ä»¶çš„æ¡ç›®
		if hasKeyword(item.Title, c.Keywords) {
			urls = append(urls, cleanUrl)
			urlToItem[cleanUrl] = item
		}
	}

	if len(urls) == 0 {
		return
	}

	// 2. æ‰¹é‡æŸ¥è¯¢å·²å­˜åœ¨çš„é€šçŸ¥
	existingMap := db.GetNotifyHistoryBatch(c.ChatId, urls)

	// 3. å¤„ç†æ–°é€šçŸ¥
	var newNotifications []*db.NotifyHistory

	for url, item := range urlToItem {
		// æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
		if existingMap[url] {
			continue
		}

		// æ·»åŠ åˆ°æ–°é€šçŸ¥åˆ—è¡¨
		newNotifications = append(newNotifications, &db.NotifyHistory{
			ChatId: c.ChatId,
			Url:    url,
			Title:  item.Title,
		})

		// å‘é€æ¶ˆæ¯
		if f.bot != nil {
			msg := NotifyMessage{
				Text: fmt.Sprintf("ğŸ“¢  *%s*\n\nğŸ• %s\n\nğŸ‘‰ %s",
					item.Title,
					item.PublishedParsed.Add(time.Hour*8).Format("2006-01-02 15:04:05"),
					url),
				ChatId: &c.ChatId,
			}

			f.Add(msg)
		}
	}

	// 4. æ‰¹é‡æ’å…¥æ–°é€šçŸ¥è®°å½•
	if len(newNotifications) > 0 {
		err := db.AddNotifyHistoryBatch(newNotifications)
		if err != nil {
			f.logger.Errorw("æ‰¹é‡æ·»åŠ é€šçŸ¥å†å²å¤±è´¥", logx.Field("err", err), logx.Field("count", len(newNotifications)))
		}
	}
}

var isRunning bool

func (f *NsFeed) loadRssData(url string, ctx context.Context) (*gofeed.Feed, error) {
	defer func() {
		rescue.Recover()
	}()
	fp := gofeed.NewParser()
	//fix:
	if strings.Contains(url, "nodeloc_rss") {
		return fp.ParseURLWithContext(url, ctx)
	}
	reqClient := req.C().ImpersonateChrome()
	resp, err := reqClient.R().Get(url)
	if err != nil {
		return nil, err
	}

	return fp.ParseString(resp.String())
}

func (f *NsFeed) adjustInterval(rss string, success bool) {
	f.Lock()
	defer f.Unlock()
	l := logx.WithContext(context.Background()).WithFields(logx.Field("rss", rss))
	if success {
		f.failureCount = 0
		f.successCount++

		// è¿ç»­æˆåŠŸ10æ¬¡åï¼Œå°è¯•å‡å°‘é—´éš”
		if f.successCount >= 10 {
			newInterval := f.interval - (5 * time.Second)
			if newInterval >= f.minInterval {
				f.interval = newInterval
				l.Infow(fmt.Sprintf("RSSè¯·æ±‚ç¨³å®šï¼Œå‡å°‘é—´éš”è‡³ %v", f.interval))
			}
			f.successCount = 0
		}
	} else {
		f.successCount = 0
		f.failureCount++

		// å¤±è´¥åç«‹å³å¢åŠ é—´éš”
		multiplier := float64(f.failureCount)
		if multiplier > 4 {
			multiplier = 4 // é™åˆ¶æœ€å¤§å€æ•°
		}

		newInterval := time.Duration(float64(f.interval) * (1 + (0.5 * multiplier)))
		if newInterval <= f.maxInterval {
			f.interval = newInterval
			l.Infow(fmt.Sprintf("RSSè¯·æ±‚å¤±è´¥ï¼Œå¢åŠ é—´éš”è‡³ %v", f.interval))
		} else {
			f.interval = f.maxInterval
			l.Infow(fmt.Sprintf("RSSè¯·æ±‚è¾¾åˆ°æœ€å¤§é—´éš” %v", f.maxInterval))
		}
	}
}

func (f *NsFeed) fetchRssAdaptive(feed *db.FeedConfig) error {
	defer rescue.Recover()

	resp, err := f.loadRssData(feed.FeedUrl, f.ctx)

	if err != nil || resp == nil {
		logx.Errorw("è·å–RSSå¤±è´¥",
			logx.Field("err", err),
			logx.Field("feedUrl", feed.FeedUrl),
		)

		f.adjustInterval(feed.FeedUrl, false)
		return err
	}

	// è¯·æ±‚æˆåŠŸ
	f.adjustInterval(feed.FeedUrl, true)

	if len(resp.Items) == 0 {
		return nil
	}

	f.Lock()
	defer f.Unlock()

	// è·å–æ‰€æœ‰æ´»è·ƒè®¢é˜…
	subscribes := db.ListSubscribes()
	subscribes = funk.Filter(subscribes, func(c *db.Subscribe) bool {
		c.Status = strings.ToLower(c.Status)
		c.Status = strings.TrimSpace(c.Status)
		return c.Status == "on" || c.Status == ""
	}).([]*db.Subscribe)

	if len(subscribes) == 0 {
		return nil
	}

	// ä½¿ç”¨å·¥ä½œæ± æ¨¡å¼å¤„ç†è®¢é˜…æ¶ˆæ¯
	// åˆ›å»ºä»»åŠ¡é€šé“
	type subscribeTask struct {
		subscribe *db.Subscribe
		items     []*gofeed.Item
	}

	// ä¼°ç®—ä»»åŠ¡æ€»æ•°
	taskCount := len(subscribes)
	if taskCount == 0 {
		return nil
	}

	// åˆ›å»ºä»»åŠ¡é€šé“ï¼Œç¼“å†²å¤§å°ä¸ºä»»åŠ¡æ€»æ•°
	taskChan := make(chan subscribeTask, taskCount)

	// åˆ›å»ºå·¥ä½œæ± 
	const workerCount = 5 // å·¥ä½œåç¨‹æ•°é‡ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
	var workerWg sync.WaitGroup

	// å¯åŠ¨å·¥ä½œåç¨‹
	for i := 0; i < workerCount; i++ {
		workerWg.Add(1)
		go func() {
			defer workerWg.Done()
			defer rescue.Recover()

			for task := range taskChan {
				subKeys := db.ListSubscribeFeedWith(task.subscribe.ChatId, feed.FeedId)
				if subKeys.ID == 0 {
					continue
				}

				f.sendMessage(&MessageOption{
					ChatId:   task.subscribe.ChatId,
					FeedName: feed.Name,
					Keywords: subKeys.KeywordsArray,
				}, feed.Name, task.items)
			}
		}()
	}

	// åˆ†å‘ä»»åŠ¡
	for _, subscribe := range subscribes {
		taskChan <- subscribeTask{
			subscribe: subscribe,
			items:     resp.Items,
		}
	}

	// å…³é—­ä»»åŠ¡é€šé“ï¼Œè¡¨ç¤ºæ²¡æœ‰æ›´å¤šä»»åŠ¡
	close(taskChan)

	// ç­‰å¾…æ‰€æœ‰å·¥ä½œåç¨‹å®Œæˆ
	workerWg.Wait()

	return nil
}

func (f *NsFeed) startAdaptiveFetch() {
	// åˆ›å»ºä¸€ä¸ªå·¥ä½œæ± æ¥å¤„ç†RSSæºçš„æŠ“å–
	const workerCount = 3 // å·¥ä½œåç¨‹æ•°é‡ï¼Œå¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

	// åˆ›å»ºä»»åŠ¡é€šé“
	type fetchTask struct {
		feed          db.FeedConfig
		interval      time.Duration
		minInterval   time.Duration
		maxInterval   time.Duration
		successCount  int
		failureCount  int
		nextFetchTime time.Time
	}

	// åˆå§‹åŒ–ä»»åŠ¡åˆ—è¡¨
	var tasks []fetchTask
	for _, feed := range db.ListAllFeedConfig() {
		tasks = append(tasks, fetchTask{
			feed:          feed,
			interval:      10 * time.Second,
			minInterval:   10 * time.Second,
			maxInterval:   5 * time.Minute,
			successCount:  0,
			failureCount:  0,
			nextFetchTime: time.Now(),
		})
	}

	// å¯åŠ¨è°ƒåº¦å™¨
	go func() {
		defer rescue.Recover()

		// åˆ›å»ºä»»åŠ¡é€šé“
		taskChan := make(chan *fetchTask, len(tasks))

		// å¯åŠ¨å·¥ä½œåç¨‹
		var wg sync.WaitGroup
		for i := 0; i < workerCount; i++ {
			wg.Add(1)
			go func() {
				defer wg.Done()
				defer rescue.Recover()

				for task := range taskChan {
					ctx := logx.ContextWithFields(context.Background(), logx.Field("rss", task.feed.FeedUrl))

					if err := f.fetchRssAdaptive(&task.feed); err != nil {
						task.failureCount++
						task.successCount = 0

						multiplier := float64(task.failureCount)
						if multiplier > 4 {
							multiplier = 4 // é™åˆ¶æœ€å¤§å€æ•°
						}

						newInterval := time.Duration(float64(task.interval) * (1 + (0.5 * multiplier)))
						if newInterval <= task.maxInterval {
							task.interval = newInterval
							logx.WithContext(ctx).Infow(fmt.Sprintf("RSSè¯·æ±‚å¤±è´¥ï¼Œå¢åŠ é—´éš”è‡³ %v", task.interval))
						} else {
							task.interval = task.maxInterval
							logx.WithContext(ctx).Infow(fmt.Sprintf("RSSè¯·æ±‚è¾¾åˆ°æœ€å¤§é—´éš” %v", task.maxInterval))
						}
					} else {
						task.failureCount = 0
						task.successCount++

						if task.successCount >= 10 {
							newInterval := task.interval - (5 * time.Second)
							if newInterval >= task.minInterval {
								task.interval = newInterval
								logx.WithContext(ctx).Infow(fmt.Sprintf("RSSè¯·æ±‚ç¨³å®šï¼Œå‡å°‘é—´éš”è‡³ %v", task.interval))
							}
							task.successCount = 0
						}
					}

					// æ›´æ–°ä¸‹æ¬¡æŠ“å–æ—¶é—´
					task.nextFetchTime = time.Now().Add(task.interval)
				}
			}()
		}

		// ä¸»å¾ªç¯ï¼Œè°ƒåº¦ä»»åŠ¡
		ticker := time.NewTicker(1 * time.Second)
		defer ticker.Stop()

		for {
			select {
			case <-f.ctx.Done():
				close(taskChan)
				wg.Wait()
				return

			case <-ticker.C:
				now := time.Now()

				// æ£€æŸ¥æ¯ä¸ªä»»åŠ¡ï¼Œå¦‚æœåˆ°äº†æ‰§è¡Œæ—¶é—´å°±å‘é€åˆ°ä»»åŠ¡é€šé“
				for i := range tasks {
					if now.After(tasks[i].nextFetchTime) {
						select {
						case taskChan <- &tasks[i]:
							// ä¸´æ—¶è®¾ç½®ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´ä¸ºå¾ˆä¹…ä»¥åï¼Œé˜²æ­¢é‡å¤è°ƒåº¦
							// å®é™…çš„ä¸‹æ¬¡æ‰§è¡Œæ—¶é—´ä¼šåœ¨ä»»åŠ¡å®Œæˆåæ›´æ–°
							tasks[i].nextFetchTime = now.Add(24 * time.Hour)
						default:
							// ä»»åŠ¡é€šé“å·²æ»¡ï¼Œè·³è¿‡
						}
					}
				}
			}
		}
	}()
}

func (f *NsFeed) Start() {
	defer func() {
		rescue.Recover()
	}()
	f.logger.Infow("start ns feed......")

	f.startAdaptiveFetch()
}
