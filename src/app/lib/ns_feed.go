package lib

import (
	"context"
	"fmt"
	"net/url"
	"strings"
	"sync"
	"time"

	"ns-rss/src/app/config"
	"ns-rss/src/app/db"

	"github.com/dlclark/regexp2"
	"github.com/imroc/req/v3"
	"github.com/mmcdole/gofeed"
	"github.com/thoas/go-funk"
	"github.com/zeromicro/go-zero/core/logx"
	"github.com/zeromicro/go-zero/core/rescue"
	"github.com/zeromicro/go-zero/core/threading"
)

//var history = make(map[int64]map[string]struct{})

// å‘é€è®¡æ•°
//var noticeHistory = make(map[string]int64)

type NsFeed struct {
	sync.Mutex
	ctx          context.Context
	svc          *ServiceCtx
	logger       logx.Logger
	bot          BotNotifier
	msgQueue     chan *NotifyMessage // æ¶ˆæ¯é˜Ÿåˆ—
	Config       *config.Config
	LastUpdate   time.Time
	interval     time.Duration // å½“å‰è¯·æ±‚é—´éš”
	minInterval  time.Duration // æœ€å°é—´éš”
	maxInterval  time.Duration // æœ€å¤§é—´éš”
	successCount int           // è¿ç»­æˆåŠŸæ¬¡æ•°
	failureCount int           // è¿ç»­å¤±è´¥æ¬¡æ•°
}

func NewNsFeed(ctx context.Context, svc *ServiceCtx, config *config.Config) *NsFeed {
	return &NsFeed{
		ctx:         ctx,
		svc:         svc,
		logger:      logx.WithContext(ctx).WithFields(logx.Field("lib", "ns_feed")),
		Config:      config,
		interval:    10 * time.Second,                // åˆå§‹é—´éš”
		minInterval: 10 * time.Second,                // æœ€å°é—´éš”
		maxInterval: 5 * time.Minute,                 // æœ€å¤§é—´éš”
		msgQueue:    make(chan *NotifyMessage, 1000), // åˆ›å»ºæ¶ˆæ¯é˜Ÿåˆ—ï¼Œç¼“å†²å¤§å°ä¸º1000
	}
}

func (f *NsFeed) SetBot(bot BotNotifier) *NsFeed {
	f.bot = bot

	// å¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹è€…
	go f.startQueueConsumer()

	return f
}

// å¯åŠ¨æ¶ˆæ¯é˜Ÿåˆ—æ¶ˆè´¹è€…ï¼Œæ§åˆ¶æ¶ˆè´¹é€Ÿç‡ä¸ºæ¯ç§’20æ¡æ¶ˆæ¯
func (f *NsFeed) startQueueConsumer() {
	defer rescue.Recover()

	f.logger.Infow("starting message queue consumer")

	// è®¡ç®—æ¶ˆæ¯å‘é€é—´éš”ï¼Œä¿è¯æ¯ç§’æœ€å¤šå‘é€20æ¡æ¶ˆæ¯
	interval := time.Millisecond * 50 // 1000ms / 20 = 50ms

	ticker := time.NewTicker(interval)
	defer ticker.Stop()

	for {
		select {
		case <-f.ctx.Done():
			f.logger.Infow("message queue consumer stopped due to context done")
			return
		case msg := <-f.msgQueue:
			<-ticker.C // ç­‰å¾…ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹

			// ç›´æ¥å‘é€æ¶ˆæ¯ï¼Œä¸ä½¿ç”¨æ—¶é—´è½®
			if msg != nil && f.bot != nil {
				f.logger.Debugw("sending message from queue", logx.Field("chatId", msg.ChatId))
				f.bot.Notify(*msg)
			}
		}
	}
}

func (f *NsFeed) Add(msg NotifyMessage) {
	// å°†æ¶ˆæ¯æ·»åŠ åˆ°é˜Ÿåˆ—
	select {
	case f.msgQueue <- &msg:
		f.logger.Debugw("added message to queue", logx.Field("chatId", msg.ChatId))
	default:
		// é˜Ÿåˆ—å·²æ»¡ï¼Œè®°å½•æ—¥å¿—
		f.logger.Infow("message queue is full, message dropped", logx.Field("chatId", msg.ChatId))
	}
}

func hasKeywordWithRegex(title string, keyword string) bool {
	//å°è¯•è½¬ä¸ºæ­£åˆ™
	re, err := regexp2.Compile(keyword, regexp2.IgnoreCase)
	if err != nil {
		return false
	}
	r, _ := re.MatchString(title)
	return r
}

func hasKeyword(title string, keywords []string) bool {
	title = strings.ToLower(title)
	for _, keyword := range keywords {
		resultChan := make(chan bool, 2)
		// å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªæ£€æŸ¥å‡½æ•°
		go func() {
			resultChan <- hasKeywordWithExpression(title, keyword)
		}()
		go func() {
			resultChan <- hasKeywordWithRegex(title, keyword)
		}()
		if result := <-resultChan; result {
			return true
		}

		if result := <-resultChan; result {
			return true
		}
	}
	return false
}

// matchExpression åŒ¹é…è¡¨è¾¾å¼å‡½æ•°
// expr: è¡¨è¾¾å¼å­—ç¬¦ä¸²ï¼Œæ”¯æŒ + (ä¸), | (æˆ–), ~ (æ’é™¤)
// text: è¦åŒ¹é…çš„æ–‡æœ¬
// è¿”å›: æ˜¯å¦åŒ¹é…çš„å¸ƒå°”å€¼
func matchExpression(expr, text string) bool {
	// é¦–å…ˆå¤„ç† | (æˆ–) è¿ç®—ç¬¦ï¼Œå°†è¡¨è¾¾å¼æŒ‰ | åˆ†å‰²
	orParts := strings.Split(expr, "|")

	// ä»»æ„ä¸€ä¸ª or æ¡ä»¶æ»¡è¶³å³è¿”å› true
	for _, orPart := range orParts {
		if matchAndExpression(strings.TrimSpace(orPart), text) {
			return true
		}
	}
	return false
}

// matchAndExpression å¤„ç† + (ä¸) å’Œ ~ (æ’é™¤) çš„é€»è¾‘
func matchAndExpression(expr, text string) bool {
	// å°†è¡¨è¾¾å¼æŒ‰ + åˆ†å‰²
	andParts := strings.Split(expr, "+")

	// æ£€æŸ¥æ¯ä¸ªæ¡ä»¶
	for _, part := range andParts {
		part = strings.TrimSpace(part)
		if len(part) == 0 {
			continue
		}

		// å¤„ç†æ’é™¤(~)é€»è¾‘
		if strings.HasPrefix(part, "~") {
			excludeTerm := strings.TrimPrefix(part, "~")
			if strings.Contains(text, excludeTerm) {
				return false
			}
		} else {
			// å¤„ç†åŒ…å«é€»è¾‘
			if !strings.Contains(text, part) {
				return false
			}
		}
	}
	return true
}

func hasKeywordWithExpression(title string, keyword string) bool {

	return matchExpression(keyword, title)

	// keyword = strings.Trim(keyword, "{}")
	// keyword = strings.ToLower(keyword)
	// // å¤„ç†æˆ–å…³ç³» (|)
	// orParts := strings.Split(keyword, "|")
	// if len(orParts) == 1 {
	// 	return strings.Contains(title, keyword)
	// }
	// for _, orPart := range orParts {
	// 	orPart = strings.TrimSpace(orPart)

	// 	// å¤„ç†ä¸å…³ç³» (+) å’Œéå…³ç³» (~)
	// 	andParts := strings.Split(orPart, "+")
	// 	allAndPartsMatch := true

	// 	for _, andPart := range andParts {
	// 		andPart = strings.TrimSpace(andPart)

	// 		// å¤„ç†éå…³ç³» (~)
	// 		notParts := strings.Split(andPart, "~")
	// 		mainKeyword := strings.TrimSpace(notParts[0])

	// 		// æ£€æŸ¥ä¸»å…³é”®å­—æ˜¯å¦å­˜åœ¨
	// 		if !strings.Contains(title, mainKeyword) {
	// 			allAndPartsMatch = false
	// 			break
	// 		}

	// 		// æ£€æŸ¥æ’é™¤å…³é”®å­—
	// 		for i := 1; i < len(notParts); i++ {
	// 			notKeyword := strings.TrimSpace(notParts[i])
	// 			if strings.Contains(title, notKeyword) {
	// 				allAndPartsMatch = false
	// 				break
	// 			}
	// 		}

	// 		if !allAndPartsMatch {
	// 			break
	// 		}
	// 	}

	// 	// å¦‚æœæ‰€æœ‰ AND æ¡ä»¶éƒ½åŒ¹é…ï¼Œè¿”å› true
	// 	if allAndPartsMatch {
	// 		return true
	// 	}
	// }
	// return false
}

type MessageOption struct {
	ChatId   int64
	FeedName string
	Keywords []string
}

func removeHash(u string) (string, error) {
	parsedUrl, err := url.Parse(u)
	if err != nil {
		return "", err
	}
	// å°†é”šç‚¹éƒ¨åˆ†è®¾ç½®ä¸ºç©º
	parsedUrl.Fragment = ""
	return parsedUrl.String(), nil
}

func (f *NsFeed) sendMessage(c *MessageOption, feedName string, items []*gofeed.Item) {

	for _, item := range items {
		item.Link, _ = removeHash(item.Link)
		if item.Link == "" {
			continue
		}
		exists := db.GetNotifyHistory(c.ChatId, item.Link) != nil
		if hasKeyword(item.Title, c.Keywords) && !exists {

			db.AddNotifyHistory(&db.NotifyHistory{
				ChatId: c.ChatId,
				Url:    item.Link,
				Title:  item.Title,
			})
			if f.bot != nil {
				msg := NotifyMessage{
					Text: fmt.Sprintf("ğŸ“¢  *%s*\n\nğŸ• %s\n\nğŸ‘‰ %s",
						item.Title,
						item.PublishedParsed.Add(time.Hour*8).Format("2006-01-02 15:04:05"),
						item.Link),
					ChatId: &c.ChatId,
				}

				f.bot.Notify(msg)
			}
		}
	}

}

var isRunning bool

func (f *NsFeed) loadRssData(url string, ctx context.Context) (*gofeed.Feed, error) {
	defer func() {
		rescue.Recover()
	}()
	fp := gofeed.NewParser()
	//fix:
	if strings.Contains(url, "nodeloc_rss") {
		return fp.ParseURLWithContext(url, ctx)
	}
	reqClient := req.C().ImpersonateChrome()
	resp, err := reqClient.R().Get(url)
	if err != nil {
		return nil, err
	}

	return fp.ParseString(resp.String())
}

func (f *NsFeed) fetchRss() {
	if isRunning {
		fmt.Println("fetch rss is running")
		return
	}
	isRunning = true
	defer func() {
		isRunning = false
	}()
	feedCnf := db.ListAllFeedConfig()

	if len(feedCnf) == 0 {
		f.logger.Errorw("fetch rss failed", logx.Field("err", "feed config is empty"))
		return
	}
	feedItems := make(map[string][]*gofeed.Item)
	var mux sync.Mutex
	var wg threading.RoutineGroup
	for _, cnf := range feedCnf {
		cnf := cnf
		wg.RunSafe(func() {
			ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
			defer cancel()

			feed, err := f.loadRssData(cnf.FeedUrl, ctx)
			if err != nil {
				f.logger.Errorw("fetch rss failed", logx.Field("err", err), logx.Field("feedUrl", cnf.FeedUrl))
				return
			}
			if feed == nil {
				f.logger.Errorw("fetch rss failed", logx.Field("err", "feed is nil"), logx.Field("feedUrl", cnf.FeedUrl))
				return
			}
			var items []*gofeed.Item
			for _, item := range feed.Items {
				items = append(items, item)
			}
			mux.Lock()
			feedItems[cnf.FeedId] = items
			mux.Unlock()
		})
	}
	wg.Wait()

	subscribes := db.ListSubscribes()
	subscribes = funk.Filter(subscribes, func(c *db.Subscribe) bool {
		c.Status = strings.ToLower(c.Status)
		c.Status = strings.TrimSpace(c.Status)
		return c.Status == "on" || c.Status == ""
	}).([]*db.Subscribe)

	var swg sync.WaitGroup

	for _, subscribe := range subscribes {
		subscribe := subscribe
		swg.Add(1)
		go func() {
			defer func() {
				swg.Done()
				rescue.Recover()
			}()
			for fid, items := range feedItems {
				subKeys := db.ListSubscribeFeedWith(subscribe.ChatId, fid)
				if subKeys.ID == 0 {
					continue
				}

				f.sendMessage(&MessageOption{
					ChatId:   subscribe.ChatId,
					FeedName: fid,
					Keywords: subKeys.KeywordsArray,
				}, fid, items)
			}
		}()
	}
	swg.Wait()
}

func (f *NsFeed) adjustInterval(rss string, success bool) {
	f.Lock()
	defer f.Unlock()
	l := logx.WithContext(context.Background()).WithFields(logx.Field("rss", rss))
	if success {
		f.failureCount = 0
		f.successCount++

		// è¿ç»­æˆåŠŸ10æ¬¡åï¼Œå°è¯•å‡å°‘é—´éš”
		if f.successCount >= 10 {
			newInterval := f.interval - (5 * time.Second)
			if newInterval >= f.minInterval {
				f.interval = newInterval
				l.Infow(fmt.Sprintf("RSSè¯·æ±‚ç¨³å®šï¼Œå‡å°‘é—´éš”è‡³ %v", f.interval))
			}
			f.successCount = 0
		}
	} else {
		f.successCount = 0
		f.failureCount++

		// å¤±è´¥åç«‹å³å¢åŠ é—´éš”
		multiplier := float64(f.failureCount)
		if multiplier > 4 {
			multiplier = 4 // é™åˆ¶æœ€å¤§å€æ•°
		}

		newInterval := time.Duration(float64(f.interval) * (1 + (0.5 * multiplier)))
		if newInterval <= f.maxInterval {
			f.interval = newInterval
			l.Infow(fmt.Sprintf("RSSè¯·æ±‚å¤±è´¥ï¼Œå¢åŠ é—´éš”è‡³ %v", f.interval))
		} else {
			f.interval = f.maxInterval
			l.Infow(fmt.Sprintf("RSSè¯·æ±‚è¾¾åˆ°æœ€å¤§é—´éš” %v", f.maxInterval))
		}
	}
}

func (f *NsFeed) fetchRssAdaptive(feed *db.FeedConfig) error {
	defer rescue.Recover()

	resp, err := f.loadRssData(feed.FeedUrl, f.ctx)

	if err != nil || resp == nil {
		logx.Errorw("è·å–RSSå¤±è´¥",
			logx.Field("err", err),
			logx.Field("feedUrl", feed.FeedUrl),
		)

		f.adjustInterval(feed.FeedUrl, false)
		return err
	}

	// è¯·æ±‚æˆåŠŸ
	f.adjustInterval(feed.FeedUrl, true)

	if len(resp.Items) == 0 {
		return nil
	}

	f.Lock()
	defer f.Unlock()

	// å…¶ä»–å¤„ç†é€»è¾‘ä¿æŒä¸å˜
	subscribes := db.ListSubscribes()
	subscribes = funk.Filter(subscribes, func(c *db.Subscribe) bool {
		c.Status = strings.ToLower(c.Status)
		c.Status = strings.TrimSpace(c.Status)
		return c.Status == "on" || c.Status == ""
	}).([]*db.Subscribe)

	var swg sync.WaitGroup

	for _, subscribe := range subscribes {
		subscribe := subscribe
		swg.Add(1)
		go func() {
			defer func() {
				swg.Done()
				rescue.Recover()
			}()
			for _, items := range resp.Items {
				subKeys := db.ListSubscribeFeedWith(subscribe.ChatId, feed.FeedId)
				if subKeys.ID == 0 {
					continue
				}

				f.sendMessage(&MessageOption{
					ChatId:   subscribe.ChatId,
					FeedName: feed.Name,
					Keywords: subKeys.KeywordsArray,
				}, feed.Name, []*gofeed.Item{items})
			}
		}()
	}
	swg.Wait()
	return nil
}

func (f *NsFeed) startAdaptiveFetch() {
	for _, feed := range db.ListAllFeedConfig() {
		feed := feed // Create a new variable for the goroutine
		go func() {
			defer func() {
				rescue.Recover()
			}()
			interval := 10 * time.Second
			minInterval := 10 * time.Second
			maxInterval := 5 * time.Minute
			successCount := 0
			failureCount := 0
			for {
				time.Sleep(interval)
				ctx := logx.ContextWithFields(context.Background(), logx.Field("rss", feed.FeedUrl))
				if err := f.fetchRssAdaptive(&feed); err != nil {
					failureCount++
					multiplier := float64(failureCount)
					if multiplier > 4 {
						multiplier = 4 // é™åˆ¶æœ€å¤§å€æ•°
					}

					newInterval := time.Duration(float64(interval) * (1 + (0.5 * multiplier)))
					if newInterval <= maxInterval {
						interval = newInterval
						logx.WithContext(ctx).Infow(fmt.Sprintf("RSSè¯·æ±‚å¤±è´¥ï¼Œå¢åŠ é—´éš”è‡³ %v", interval))
					} else {
						interval = maxInterval
						logx.WithContext(ctx).Infow(fmt.Sprintf("RSSè¯·æ±‚è¾¾åˆ°æœ€å¤§é—´éš”ï¼Œå¢åŠ é—´éš”è‡³ %v", maxInterval))
					}
				} else {
					successCount++
					if successCount >= 10 {
						newInterval := interval - (5 * time.Second)
						if newInterval >= minInterval {
							interval = newInterval
							logx.WithContext(ctx).Infow(fmt.Sprintf("RSSè¯·æ±‚ç¨³å®šï¼Œå‡å°‘é—´éš”è‡³ %v", maxInterval))
						}
						successCount = 0
					}
					failureCount = 0
				}
			}
		}()
	}
}

func (f *NsFeed) Start() {
	defer func() {
		rescue.Recover()
	}()
	f.logger.Infow("start ns feed......")
	//
	//ds, e := time.ParseDuration(f.svc.Config.FetchTimeInterval)
	//if e != nil {
	//	f.logger.Errorw("parse duration failed", logx.Field("err", e), logx.Field("FetchTimeInterval", f.svc.Config.FetchTimeInterval))
	//	ds = 10 * time.Second
	//}
	//if ds < 10*time.Second {
	//	ds = 10 * time.Second
	//}
	//go func() {
	//	defer func() {
	//		rescue.Recover()
	//	}()
	//	tk := time.NewTicker(ds)
	//	defer tk.Stop()
	//	for {
	//		select {
	//		case <-f.ctx.Done():
	//			return
	//		case <-tk.C:
	//			f.fetchRss()
	//		}
	//	}
	//}()

	f.startAdaptiveFetch()
}
